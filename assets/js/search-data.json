{
  
    
        "post0": {
            "title": "How to keep up to date with all the covid data automatically",
            "content": "Keeping up with the ups and downs of a pandemic is not an easy task as a data scientist . This text explains the code below . import pandas as pd import pycountry covid_data_url = &#39;https://covid.ourworldindata.org/data/owid-covid-data.csv&#39; stringency_api_url = &#39;https://covidtrackerapi.bsg.ox.ac.uk/api/stringency&#39; def covid(): import pandas as pd df = pd.read_csv(covid_data_url) df[&#39;date&#39;] = pd.to_datetime(df[&#39;date&#39;]) df = df.drop(columns=[&#39;continent&#39;,&#39;stringency_index&#39;,&#39;location&#39;,&#39;tests_units&#39;]).pivot(index=&#39;date&#39;,columns=[&#39;iso_code&#39;]).sort_values(by=&#39;date&#39;).select_dtypes([&#39;number&#39;]).apply(pd.to_numeric, errors=&#39;coerce&#39;).drop_duplicates().dropna(axis=1,how=&#39;all&#39;).head(-1) #todo make all columns floats df.columns.names = [&#39;variable&#39;, &#39;iso_code&#39;] start_date = df.index.min() now_date = df.index.max() import datetime as dt import requests as req now_date = str(now_date.strftime(&#39;%Y-%m-%d&#39;)).replace(&quot;&#39;&quot;, &quot;&quot;) start_date = str(start_date.strftime(&#39;%Y-%m-%d&#39;)).replace(&quot;&#39;&quot;, &quot;&quot;) now_date1 = str(dt.datetime.now().strftime(&#39;%Y-%m-%d&#39;)).replace(&quot;&#39;&quot;, &quot;&quot;) stringency_api = f&quot;{stringency_api_url}/date-range/{start_date}/{now_date}&quot; stringency_df = pd.DataFrame.from_dict( req.get(stringency_api).json()[&#39;data&#39;], orient=&#39;index&#39;) def extract_stringency(stringency_series, start_date=&#39;2020-01-02&#39;, end_date = dt.datetime.now().strftime(&#39;%Y-%m-%d&#39;)): try: df = pd.DataFrame().from_dict( {i[&#39;date_value&#39;]: [i[&#39;stringency&#39;]] for i in stringency_series.values if not pd.isna(i)} , orient=&#39;index&#39;).rename(columns={0: stringency_series.name}) df = df.set_index(pd.DatetimeIndex(pd.to_datetime(df.index.values, format=&#39;%Y-%m-%d&#39;), name=&#39;day&#39;)).groupby( level=0).mean() # in case of double values per day, take their mean df = df.reindex(pd.date_range(start=start_date, end= end_date)) df.interpolate(method=&#39;linear&#39;, inplace=True) return df except: pass def stringency_data_df(stringency_df): data_df = pd.DataFrame([]) for iso_alpha in stringency_df.columns: data_df = pd.concat([ data_df, extract_stringency(stringency_df[iso_alpha], end_date=df.index.max().strftime(&#39;%Y-%m-%d&#39;)) ], axis=1) return data_df stringency = pd.concat([stringency_data_df(stringency_df)],keys = [&#39;stringency&#39;],names=[&#39;iso_code&#39;],axis=1) df = pd.concat([df,stringency],axis=1) return df . visualisation . from sklearn.preprocessing import QuantileTransformer def covid_map_df(covid_data): &quot;&quot;&quot; covid map contains: name of the country alpha_3 &quot;&quot;&quot; qt = QuantileTransformer(n_quantiles=150) pd.DataFrame(covid_data.loc[covid_data.index.max()]).columns#pivot(index = &#39;iso_code&#39;,columns=&#39;variable&#39;) covid_map = pd.DataFrame(covid_data.loc[covid_data.index.max()]).unstack(level=0)#.dropna() covid_map.columns = covid_map.columns.get_level_values(1).values for col in covid_map.filter(regex=&quot;_per&quot;).columns: new_col_name = str(col + &#39;_relative_change&#39;) covid_map[new_col_name] = qt.fit_transform(covid_map[col].values.reshape(-1, 1)) covid_map.index.name = &#39;alpha_3&#39; covid_map.reset_index(inplace=True) # not every iso_code has a full name via pycountry covid_map[&#39;name&#39;] = covid_map[&#39;alpha_3&#39;].apply(lambda cd: pycountry.countries.get(alpha_3=cd).name if pycountry.countries.get(alpha_3=cd) else cd) return covid_map . cols_dd = list(set(chloropleth_df.columns.tolist()) - {&#39;iso_code&#39;,&#39;location&#39;,&#39;tests performed&#39;,&#39;tests_units&#39;}) visible = np.array(cols_dd) df = chloropleth_df # define traces and buttons at once traces = [] buttons = [] for value in cols_dd: traces.append(go.Choropleth( locations=df[&#39;iso_code&#39;], # Spatial coordinates z=df[value].astype(float), # Data to be color-coded colorbar_title=value, visible= True if value==cols_dd[0] else False)) buttons.append(dict(label=value, method=&quot;update&quot;, args=[{&quot;visible&quot;:list(visible==value)}, {&quot;title&quot;:f&quot;&lt;b&gt;{value}&lt;/b&gt;&quot;}])) updatemenus = [{&quot;active&quot;:0, &quot;buttons&quot;:buttons, }] # Show figure fig = go.Figure(data=traces, layout=dict(updatemenus=updatemenus)) # This is in order to get the first title displayed correctly first_title = cols_dd[0] fig.update_layout(title=f&quot;&lt;b&gt;{first_title}&lt;/b&gt;&quot;,title_x=0.5) fig.show() . . . We want to store all this data in a central database, to simulate this for development we will run a local server. But in production switch the database url for prod url. . !pip install flask_sqlalchemy sqlalchemy-media psycopg2-binary --quiet # install !apt install postgresql postgresql-contrib &amp;&gt;log !service postgresql start !sudo -u postgres psql -c &quot;CREATE USER root WITH SUPERUSER&quot; # set connection %load_ext sql %config SqlMagic.feedback=False %config SqlMagic.autopandas=True %sql postgresql+psycopg2://@/postgres . |████████████████████████████████| 1.3MB 5.7MB/s |████████████████████████████████| 3.0MB 27.0MB/s Building wheel for sqlalchemy-media (setup.py) ... done * Starting PostgreSQL 10 database server ...done. CREATE ROLE . &#39;Connected: @postgres&#39; . In production switch this to the appropriate format for your database . from sqlalchemy import create_engine local_engine = create_engine(&#39;postgresql+psycopg2://@/postgres&#39;) . Then we need to store the data, however since the dataframe has . def to_sql(df, name, con, if_exists=&#39;fail&#39;,chunksize=3276): if not df.index.name: df.index.name = &#39;idx&#39; if not df.columns.name: df.columns.name = &#39;col&#39; df.rename_axis(index=str.lower).unstack().rename_axis(index=str.lower).reset_index().set_index( df.index.name.lower()).sort_values( by=[df.index.name.lower()] + [col.lower() for col in list(df.columns.names)]).to_sql(name, con=con, if_exists=if_exists, method=&#39;multi&#39;, chunksize=chunksize, index=True) . # read SQL def read_sql(name: str, con: sa.engine.base.Engine, column_filter=None, row_filter=None) -&gt; pd.DataFrame: &quot;&quot;&quot; :name: name of the the in the db :con: sqlalchemy connection engine :column_filter: dict in format {0:[&#39;value_0&#39;,&#39;value_1&#39;],1:[&#39;value&#39;]}, where 0 refers to the level of the multiindex column :row_filter: dict if format {&#39;from&#39;:&#39;2010-01-01&#39;,&#39;to&#39;:&#39;2011-01-01&#39;} or {&#39;last&#39;:&#39;10Q&#39;} &quot;&quot;&quot; if not con.has_table(name): # check whether the table exists raise Exception(f&quot;Table {name} does not exist&quot;) else: type_dict = sa.inspect(con).get_columns(name) index_col = [ col[&#39;name&#39;] for col in type_dict if any(datetype in col[&#39;type&#39;].__str__() for datetype in [&#39;TIMESTAMP&#39;,&#39;DATE&#39;]) ][0] stack_cols = [col[&#39;name&#39;] for col in type_dict if &#39;TEXT&#39; in col[&#39;type&#39;].__str__()] value_col = [col[&#39;name&#39;] for col in type_dict if (&#39;DOUBLE&#39; in col[&#39;type&#39;].__str__() or &#39;INT&#39; in col[&#39;type&#39;].__str__())][ 0] params = tuple() query = f&quot;SELECT * FROM {name}&quot; # base query if column_filter: # select which column to fetch from db query += f&quot; WHERE &quot; query += &quot; AND &quot;.join([f&quot;{stack_cols[int(key)]} IN ({&#39;,&#39;.join([&#39;%s&#39; for _ in value])})&quot; for key, value in column_filter.items()]) params = tuple([value for value in chain(*column_filter.values())]) if row_filter: # select between which dates to fetch if not column_filter: query += &#39; WHERE &#39; else: query += &#39; AND &#39; if &#39;from&#39; in row_filter.keys() and not &#39;last&#39; in row_filter.keys(): query += f&quot; {index_col} &gt;= %s&quot; params += tuple([dt.datetime.fromisoformat(row_filter[&#39;from&#39;])]) if &#39;to&#39; in row_filter.keys() and not &#39;last&#39; in row_filter.keys(): if &#39;from&#39; in row_filter.keys(): query += &#39; AND &#39; query += f&quot; {index_col} &lt;= %s&quot; params += tuple([dt.datetime.fromisoformat(row_filter[&#39;to&#39;])]) if &#39;last&#39; in row_filter.keys() and not (&#39;to&#39; in row_filter.keys() or &#39;from&#39; in row_filter.keys()): query += f&quot; {index_col} &gt;= %s&quot; max_date = con.engine.execute(f&#39;SELECT MAX({index_col}) FROM {name}&#39;).fetchone()[0] params += tuple([(max_date - pd.tseries.frequencies.to_offset(row_filter[&#39;last&#39;])).to_pydatetime()]) return pd.read_sql_query(query, con=con, index_col=index_col, params=params ).pivot(columns=stack_cols, values=value_col) . def get_last_source_date(table_name:str,con)-&gt;dt.datetime: import sqlalchemy as sa type_dict = sa.inspect(con).get_columns(table_name) index_col = [ col[&#39;name&#39;] for col in type_dict if any(datetype in col[&#39;type&#39;].__str__() for datetype in [&#39;TIMESTAMP&#39;,&#39;DATE&#39;]) ][0] last_source_date = con.engine.execute(f&#39;SELECT MAX({index_col}) FROM {table_name}&#39;).fetchone()[0] return last_source_date .",
            "url": "https://hugocool.github.io/blog/2021/05/28/How_to_store_large_timeseries_in_SQL.html",
            "relUrl": "/2021/05/28/How_to_store_large_timeseries_in_SQL.html",
            "date": " • May 28, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "FAIR data science in healthcare",
            "content": "A. Data Collection . [ ] A.1 Informed consent: If there are human subjects, have they given informed consent, where subjects affirmatively opt-in and have a clear understanding of the data uses to which they consent? | [ ] A.2 Collection bias: Have we considered sources of bias that could be introduced during data collection and survey design and taken steps to mitigate those? | [x] A.3 Limit PII exposure: Have we considered ways to minimize exposure of personally identifiable information (PII) for example through anonymization or not collecting information that isn&#39;t relevant for analysis? | [x] A.4 Downstream bias mitigation: Have we considered ways to enable testing downstream results for biased outcomes (e.g., collecting data on protected group status like race or gender)? | . B. Data Storage . [x] B.1 Data security: Do we have a plan to protect and secure data (e.g., encryption at rest and in transit, access controls on internal users and third parties, access logs, and up-to-date software)? | [ ] B.2 Right to be forgotten: Do we have a mechanism through which an individual can request their personal information be removed? | [ ] B.3 Data retention plan: Is there a schedule or plan to delete the data after it is no longer needed? | . C. Analysis . [ ] C.1 Missing perspectives: Have we sought to address blindspots in the analysis through engagement with relevant stakeholders (e.g., checking assumptions and discussing implications with affected communities and subject matter experts)? | [ ] C.2 Dataset bias: Have we examined the data for possible sources of bias and taken steps to mitigate or address these biases (e.g., stereotype perpetuation, confirmation bias, imbalanced classes, or omitted confounding variables)? | [ ] C.3 Honest representation: Are our visualizations, summary statistics, and reports designed to honestly represent the underlying data? | [ ] C.4 Privacy in analysis: Have we ensured that data with PII are not used or displayed unless necessary for the analysis? | [ ] C.5 Auditability: Is the process of generating the analysis well documented and reproducible if we discover issues in the future? | . D. Modeling . [ ] D.1 Proxy discrimination: Have we ensured that the model does not rely on variables or proxies for variables that are unfairly discriminatory? | [ ] D.2 Fairness across groups: Have we tested model results for fairness with respect to different affected groups (e.g., tested for disparate error rates)? | [ ] D.3 Metric selection: Have we considered the effects of optimizing for our defined metrics and considered additional metrics? | [ ] D.4 Explainability: Can we explain in understandable terms a decision the model made in cases where a justification is needed? | [ ] D.5 Communicate bias: Have we communicated the shortcomings, limitations, and biases of the model to relevant stakeholders in ways that can be generally understood? | . E. Deployment . [ ] E.1 Redress: Have we discussed with our organization a plan for response if users are harmed by the results (e.g., how does the data science team evaluate these cases and update analysis and models to prevent future harm)? | [ ] E.2 Roll back: Is there a way to turn off or roll back the model in production if necessary? | [ ] E.3 Concept drift: Do we test and monitor for concept drift to ensure the model remains fair over time? | [ ] E.4 Unintended use: Have we taken steps to identify and prevent unintended uses and abuse of the model and do we have a plan to monitor these once the model is deployed? | . Explaining the predictions . generating a checklist . !pip install deon --quiet !deon .",
            "url": "https://hugocool.github.io/blog/2021/05/28/Explaining_the_prediction_of_diabetes.html",
            "relUrl": "/2021/05/28/Explaining_the_prediction_of_diabetes.html",
            "date": " • May 28, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://hugocool.github.io/blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://hugocool.github.io/blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://hugocool.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://hugocool.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}